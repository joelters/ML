% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modest.R
\name{modest}
\alias{modest}
\title{Estimate Machine Learning model}
\usage{
modest(
  X,
  Y,
  ML = c("Lasso", "Ridge", "RF", "CIF", "XGB", "CB", "Torch", "NLLS_exp", "loglin",
    "Logit_lasso", "OLS", "grf", "SL", "OLSensemble"),
  OLSensemble,
  SL.library,
  rf.cf.ntree = 500,
  rf.depth = NULL,
  mtry = max(floor(ncol(X)/3), 1),
  cf.depth = Inf,
  polynomial.Lasso = 1,
  polynomial.Ridge = 1,
  polynomial.Logit_lasso = 1,
  polynomial.OLS = 1,
  polynomial.NLLS_exp = 1,
  polynomial.loglin = 1,
  start_nlls = NULL,
  ensemblefolds = 10,
  xgb.nrounds = 200,
  xgb.max.depth = 6,
  cb.iterations = 500,
  cb.depth = 6,
  torch.epochs = 50,
  torch.hidden_units = c(64, 32),
  torch.lr = 0.01,
  torch.dropout = 0.2,
  weights = NULL
)
}
\arguments{
\item{X}{is a dataframe containing all the features}

\item{Y}{is a vector containing the label}

\item{ML}{is a string specifying which machine learner to use}

\item{OLSensemble}{is a string vector specifying which learners
should be used in OLS ensemble method}

\item{SL.library}{is a string vector specifying which learners
should be used in SuperLearner}

\item{rf.cf.ntree}{how many trees should be grown when using RF or CIF}

\item{rf.depth}{how deep should trees be grown in RF (NULL is default from ranger)}

\item{cf.depth}{how deep should trees be grown in CIF (Inf is default from partykit)}

\item{polynomial.Lasso}{degree of polynomial to be fitted when using Lasso.
1 just fits the input X. 2 squares all variables and adds
all pairwise interactions. 3 squares and cubes all variables and adds all
pairwise and threewise interactions...}

\item{polynomial.Ridge}{degree of polynomial to be fitted when using Ridge,
see polynomial.Lasso for more info.}

\item{polynomial.Logit_lasso}{degree of polynomial to be fitted when using Logit_lasso,
see polynomial.Lasso for more info.}

\item{polynomial.OLS}{degree of polynomial to be fitted when using OLS,
see polynomial.Lasso for more info.}

\item{polynomial.NLLS_exp}{degree of polynomial to be fitted when using NLLS_exp,
see polynomial.Lasso for more info.}

\item{polynomial.loglin}{degree of polynomial to be fitted when using loglin,
see polynomial.Lasso for more info.}

\item{start_nlls}{List with the starting values of the parameters. Default is log(mean(Y))
for the intercept and zero for all the rest.}

\item{ensemblefolds}{is an integer specifying how many folds to use in ensemble
methods such as OLSensemble or SuperLearner}

\item{xgb.nrounds}{is an integer specifying how many rounds to use in XGB}

\item{xgb.max.depth}{is an integer specifying how deep trees should be grown in XGB}

\item{cb.iterations}{The maximum number of trees that can be built in CB}

\item{cb.depth}{The depth of the trees in CB}

\item{torch.epochs}{is an integer specifying the number of epochs (full passes through the dataset)
to use when training the Torch neural network.}

\item{torch.hidden_units}{is a numeric vector specifying the number of neurons
in each hidden layer of the Torch neural network.}

\item{torch.lr}{is a numeric value specifying the learning rate to be used for the
optimizer when training the Torch neural network.}

\item{torch.dropout}{is a numeric value between 0 and 1 specifying the dropout rate
for regularization in the Torch neural network.}

\item{weights}{is a vector containing survey weights adding up to 1}
}
\value{
the object that the machine learner package returns, in case of OLSensemble
it returns the coefficients assigned to each machine learner in ensemble
}
\description{
\code{modest} estimates the model for a specified machine learner,
possible options are Lasso, Ridge, Random Forest, Conditional
Inference Forest, Extreme Gradient Boosting, Catboosting, Logit Lasso,
NLLS with exp(x'b), loglin with exp(x'b) and x'b from OLS of lnY on X
or any combination of these using the SuperLearner package
}
\details{
Note that the glmnet package
which implements Lasso and Ridge does not handle factor variables
(such as the ones in mad2019), hence for this machine learners,
modest turns X into model.matrix(~.,X) which will perform dummy
encoding on factor variables.
}
\examples{
X <- dplyr::select(mad2019,-Y)
Y <- mad2019$Y
modest(X,Y,"RF")
modest(X,Y,"XGB")
modest(X,Y,"Lasso")
modest(X,Y,"SL",
ensemble = c("SL.Lasso","SL.Ridge","SL.RF","SL.CIF","SL.XGB","SL.CB"))

}
